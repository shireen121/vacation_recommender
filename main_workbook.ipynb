{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"index\"></a>\n",
    "# Trip Advisor\n",
    "\n",
    "In this project, I go through a number of steps to create a recommendation engine for vacation spots and activities across the globe based on user interests. The key steps are broken down as follows:  \n",
    "  \n",
    "[Step 1: Scrape reviews from TripAdvisor](#review_data)    \n",
    "[Step 2: Dimensionality reduction - LDA topic modeling with reviews](#LDA)    \n",
    "[Step 3: Calculate similarities between activities based on topic distribution of reviews](#cosine)  \n",
    "[Step 4: Create Recommendation Engine](#recommendation)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T01:51:20.918752Z",
     "start_time": "2018-01-24T01:51:18.247286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from operator import itemgetter\n",
    "from gensim import corpora, models, similarities, matutils\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity \n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Back to Top](#index)\n",
    "<a id=\"review_data\"></a>\n",
    "## Step 1: Scrape reviews from TripAdvisor\n",
    "Please note: Scrapy code is provided in separate file. Below is the import of the scraped data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in scraped files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T01:51:26.121876Z",
     "start_time": "2018-01-24T01:51:22.377759Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Selected json data files from Tripadvisor scrape, a number of cities are excluded for purposes of simplicity\n",
    "atl_reviews = pd.read_json(\"scraped_data/all_atl_reviews.json\")\n",
    "berlin_reviews = pd.read_json(\"scraped_data/all_berlin_reviews.json\")\n",
    "budapest_reviews = pd.read_json(\"scraped_data/all_budapest_reviews.json\")\n",
    "chicago_reviews = pd.read_json(\"scraped_data/all_chicago_reviews.json\")\n",
    "cusco_reviews = pd.read_json(\"scraped_data/all_cusco_reviews.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T01:51:26.914287Z",
     "start_time": "2018-01-24T01:51:26.800367Z"
    }
   },
   "outputs": [],
   "source": [
    "# Combine cities into one pandas dataframe\n",
    "dfs = [atl_reviews, berlin_reviews, budapest_reviews, chicago_reviews, cusco_reviews]\n",
    "all_reviews = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T01:51:28.030168Z",
     "start_time": "2018-01-24T01:51:27.912979Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>activity_name</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>Georgia World Congress Center</td>\n",
       "      <td>This is one if the largest and nicest convenie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>Georgia World Congress Center</td>\n",
       "      <td>I travel to a fair amount of conventions inclu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>Georgia World Congress Center</td>\n",
       "      <td>The meeting and vendors were outstanding...how...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>Georgia World Congress Center</td>\n",
       "      <td>Great place to have a concert. We sat in the b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>atlanta</td>\n",
       "      <td>Georgia World Congress Center</td>\n",
       "      <td>We were very impressed with the facility, but ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      city                  activity_name  \\\n",
       "0  atlanta  Georgia World Congress Center   \n",
       "1  atlanta  Georgia World Congress Center   \n",
       "2  atlanta  Georgia World Congress Center   \n",
       "3  atlanta  Georgia World Congress Center   \n",
       "4  atlanta  Georgia World Congress Center   \n",
       "\n",
       "                                         review_text  \n",
       "0  This is one if the largest and nicest convenie...  \n",
       "1  I travel to a fair amount of conventions inclu...  \n",
       "2  The meeting and vendors were outstanding...how...  \n",
       "3  Great place to have a concert. We sat in the b...  \n",
       "4  We were very impressed with the facility, but ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select columns for use in this analysis\n",
    "all_reviews = all_reviews[[\"city\", \"activity_name\", \"review_text\"]]\n",
    "all_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#index)\n",
    "<a id=\"LDA\"></a>\n",
    "## Step 2: Dimensionality reduction - LDA topic modeling with reviews\n",
    "\n",
    "The purpose of this step is to utilize topic modeling techniques in order to reduce the dimensionality of the TripAdvisor user reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T01:51:30.314944Z",
     "start_time": "2018-01-24T01:51:30.302891Z"
    }
   },
   "outputs": [],
   "source": [
    "review_text_only = all_reviews.iloc[:,-1].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T01:52:53.729981Z",
     "start_time": "2018-01-24T01:51:30.917886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['one largest nicest conveni center visit usher guest servic nice friendli knowledg',\n",
       " 'travel fair amount convent includ held orlando vega set one modern facil apart next staff base experi georgia world congress center runaway favorit park attend']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_stemmer = PorterStemmer()\n",
    "en_stop = stopwords.words('english') + ['.', ',', '(', ')', \"'\", '\"', \"-\", \"!\", \"!!\", \"!!!\", \"...\"]\n",
    "\n",
    "# List for tokenized documents in loop\n",
    "cleaned_reviews = []\n",
    "\n",
    "# Loop through document list\n",
    "for line in review_text_only:\n",
    "    # Clean and tokenize document string\n",
    "    raw = line.lower()\n",
    "    tokens = wordpunct_tokenize(raw)\n",
    "    \n",
    "    # Remove stop words from tokens\n",
    "    stopped_tokens = [i for i in tokens if not i in en_stop]\n",
    "    \n",
    "    # Stem tokens\n",
    "    stemmed_tokens = [p_stemmer.stem(i) for i in stopped_tokens]\n",
    "    \n",
    "    # Combine words back into reviews\n",
    "    cleaned_reviews.append(\" \".join(stemmed_tokens))\n",
    "    \n",
    "\n",
    "cleaned_reviews[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T01:52:57.063077Z",
     "start_time": "2018-01-24T01:52:53.734435Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create Count Vectorizer\n",
    "vectorizer = CountVectorizer(stop_words=en_stop, max_df=0.5)\n",
    "cv = vectorizer.fit_transform(cleaned_reviews).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T01:52:57.128203Z",
     "start_time": "2018-01-24T01:52:57.067582Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of Unique Words: 29895\n",
      "Bag of Words Matrix shape: (29895, 74862)\n"
     ]
    }
   ],
   "source": [
    "# Check number of unique words and validate matrix shape\n",
    "print(\"# of Unique Words: \" + str(len(vectorizer.get_feature_names())))\n",
    "print(\"Bag of Words Matrix shape: \" + str(cv.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T02:34:05.354847Z",
     "start_time": "2018-01-24T01:53:19.684736Z"
    }
   },
   "outputs": [],
   "source": [
    "# Run LDA model on reviews. Model runtime is lengthy (~40 min), pickle file of results available below.\n",
    "corpus = matutils.Sparse2Corpus(cv)\n",
    "id2word = dict((v, k) for k, v in vectorizer.vocabulary_.items())\n",
    "lda = models.LdaModel(corpus=corpus, num_topics=50, id2word=id2word, random_state = 21, passes=10)\n",
    "\n",
    "# Convert results from model to working format\n",
    "lda_corpus =lda[corpus]\n",
    "lda_docs = [doc for doc in lda_corpus]\n",
    "\n",
    "# Pickle results of model\n",
    "with open('lda_docs_5_cities.pkl', 'wb') as picklefile:\n",
    "    pickle.dump(lda_docs, picklefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T02:46:44.353228Z",
     "start_time": "2018-01-24T02:46:43.379009Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read in pickled results of model\n",
    "with open('lda_docs_5_cities.pkl', 'rb') as picklefile_lda:\n",
    "    lda_docs = pickle.load(picklefile_lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#index)\n",
    "<a id=\"cosine\"></a>\n",
    "## Step 3: Calculate similarity between activities based on topic distribution of reviews \n",
    "In this step, I will take the LDA topic distributions for each review and average them by activity in order to get a representative topic distribution vector for each activity. Then, I will calculate the cosine similarity between each activity in the dataset to be used in the recommendation engine to find similar activities.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process data to prepare for pairwise similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T02:46:45.765390Z",
     "start_time": "2018-01-24T02:46:45.154719Z"
    }
   },
   "outputs": [],
   "source": [
    "# Expand sparse matrix from model into full matrix for utilization in pairwise comparisons\n",
    "length = len(lda_docs) \n",
    "doc_vectors = np.zeros((length, 50))  # Initialize numpy array\n",
    "for i, doc2topics in enumerate(lda_docs):\n",
    "    for topic, percentage in doc2topics:\n",
    "        doc_vectors[i][topic] = percentage\n",
    "\n",
    "all_reviews[\"lda_vector\"] = list(doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T02:46:46.250720Z",
     "start_time": "2018-01-24T02:46:45.769965Z"
    }
   },
   "outputs": [],
   "source": [
    "# Average LDA topic distribution of each review by activity\n",
    "activity_vectors = pd.DataFrame(all_reviews.groupby([\"activity_name\", \"city\"])\n",
    "                                [\"lda_vector\"].apply(lambda x: np.mean(x, axis=0))).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T02:46:47.678908Z",
     "start_time": "2018-01-24T02:46:47.603715Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>activity_name</th>\n",
       "      <th>city</th>\n",
       "      <th>lda_vector</th>\n",
       "      <th>cosine_similarities_lda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>31st Street Harbor</td>\n",
       "      <td>chicago</td>\n",
       "      <td>[0.00699710180582, 0.00736124401914, 0.0044676...</td>\n",
       "      <td>[1.0, 0.513042600253, 0.789935793263, 0.528108...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>333 West Wacker Drive</td>\n",
       "      <td>chicago</td>\n",
       "      <td>[0.045780379994, 0.00809322447906, 0.0, 0.0, 0...</td>\n",
       "      <td>[0.513042600253, 1.0, 0.544421766284, 0.349733...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>360 Chicago Observation Deck</td>\n",
       "      <td>chicago</td>\n",
       "      <td>[0.0283879799752, 0.00474233563058, 0.01093371...</td>\n",
       "      <td>[0.789935793263, 0.544421766284, 1.0, 0.629756...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3d Gallery Budapest</td>\n",
       "      <td>budapest</td>\n",
       "      <td>[0.00412249661846, 0.00262300845502, 0.0103597...</td>\n",
       "      <td>[0.528108751076, 0.349733495365, 0.62975685397...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ACVB Visitor Center - Underground Atlanta</td>\n",
       "      <td>atlanta</td>\n",
       "      <td>[0.0, 0.0, 0.0119561989825, 0.00887876281606, ...</td>\n",
       "      <td>[0.432273473749, 0.34509709698, 0.453786622931...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                              activity_name      city  \\\n",
       "0      0                         31st Street Harbor   chicago   \n",
       "1      1                      333 West Wacker Drive   chicago   \n",
       "2      2               360 Chicago Observation Deck   chicago   \n",
       "3      3                        3d Gallery Budapest  budapest   \n",
       "4      4  ACVB Visitor Center - Underground Atlanta   atlanta   \n",
       "\n",
       "                                          lda_vector  \\\n",
       "0  [0.00699710180582, 0.00736124401914, 0.0044676...   \n",
       "1  [0.045780379994, 0.00809322447906, 0.0, 0.0, 0...   \n",
       "2  [0.0283879799752, 0.00474233563058, 0.01093371...   \n",
       "3  [0.00412249661846, 0.00262300845502, 0.0103597...   \n",
       "4  [0.0, 0.0, 0.0119561989825, 0.00887876281606, ...   \n",
       "\n",
       "                             cosine_similarities_lda  \n",
       "0  [1.0, 0.513042600253, 0.789935793263, 0.528108...  \n",
       "1  [0.513042600253, 1.0, 0.544421766284, 0.349733...  \n",
       "2  [0.789935793263, 0.544421766284, 1.0, 0.629756...  \n",
       "3  [0.528108751076, 0.349733495365, 0.62975685397...  \n",
       "4  [0.432273473749, 0.34509709698, 0.453786622931...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use LDA model results by activity for cosine similarity calculation\n",
    "activity_vectors_lda = list(activity_vectors.lda_vector)\n",
    "cosine_similarities_lda = cosine_similarity(activity_vectors_lda, activity_vectors_lda)\n",
    "activity_vectors[\"cosine_similarities_lda\"] = list(cosine_similarities_lda)\n",
    "activity_vectors = activity_vectors.reset_index()\n",
    "\n",
    "activity_vectors.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T02:46:51.308883Z",
     "start_time": "2018-01-24T02:46:49.634634Z"
    }
   },
   "outputs": [],
   "source": [
    "#Create dictionary from similarity matrix where each key is a unique activity and the values are the sorted activities based on cosine similarity \n",
    "cosine_dicts_all = []\n",
    "for idx, row in activity_vectors.iterrows():\n",
    "    similar_items_dict = {}\n",
    "    similar_indices = cosine_similarities_lda[idx].argsort()[::-1]\n",
    "    for i in similar_indices:\n",
    "        similar_items_dict[cosine_similarities_lda[idx][i]] = i\n",
    "    cosine_dicts_all.append(similar_items_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to Top](#index)\n",
    "<a id=\"recommendation\"></a>\n",
    "## Step 4: Create Recommendation Engine\n",
    "\n",
    "The recommendation engine will take user input of a city and three activities the user enjoys doing in that city and will recommend the three top locations to go and similar activities in each of those locations based on the user input.  \n",
    "    \n",
    "Please note below is the code for the recommendation engine, but the flask app I built where this is implemented in a user-friendly format is not included in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T02:46:56.970479Z",
     "start_time": "2018-01-24T02:46:56.961474Z"
    }
   },
   "outputs": [],
   "source": [
    "# Take user inputs and find the index for each activity to enable search in dictionary\n",
    "def get_index(activity_names, city):\n",
    "    act_indices=[]\n",
    "    for activity_name in activity_names:\n",
    "        act_index = int(activity_vectors[(activity_vectors[\"activity_name\"] == activity_name) & \n",
    "                         (activity_vectors[\"city\"] == city)][\"index\"])\n",
    "        act_indices.append(act_index)\n",
    "    return act_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T02:46:57.575061Z",
     "start_time": "2018-01-24T02:46:57.464759Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_recommendations(activity_names, city):\n",
    "    \n",
    "    # Get index of user selected activity names \n",
    "    act_indices = get_index(activity_names, city)\n",
    "    \n",
    "    # Reorganize activity data by city & save 3 most similar activities for each user-selected activity for each city\n",
    "    recommendations = []\n",
    "    by_city_sim = {}\n",
    "    by_city_idx = {}\n",
    "    for i, act_index in enumerate(act_indices):\n",
    "        cosine_sims = cosine_dicts_all[act_index]\n",
    "        count = Counter()\n",
    "        for key, value in cosine_sims.items():\n",
    "            cos_city = activity_vectors.iloc[value][\"city\"]\n",
    "            if cos_city == city:\n",
    "                pass\n",
    "            elif cos_city not in by_city_sim:\n",
    "                by_city_sim[cos_city] = [key]\n",
    "                by_city_idx[cos_city] = [value]\n",
    "                count[cos_city] += 1\n",
    "            elif count[cos_city] < 3 and value not in by_city_idx[cos_city]:\n",
    "                by_city_sim[cos_city].append(key)\n",
    "                by_city_idx[cos_city].append(value)\n",
    "                count[cos_city] += 1\n",
    "                if sum(count.values()) == 51:\n",
    "                    break\n",
    "            else: \n",
    "                pass\n",
    "    \n",
    "    #average similarity metrics of most similar activities for each city and select three most similar cities\n",
    "    avg_similar_acts = {}\n",
    "    for key, value in by_city_sim.items():\n",
    "        avg_similar_acts[key] = np.mean(value)\n",
    "    sorted_avg_sims = sorted(avg_similar_acts.items(),key = itemgetter(1),reverse = True)  \n",
    "    top_3_cities = list(zip(*sorted_avg_sims))[0][:3]\n",
    "    recommendations = {}\n",
    "    for key, values in by_city_idx.items():\n",
    "        if key in top_3_cities:\n",
    "            activities = [activity_vectors.iloc[val][\"activity_name\"] for val in values]\n",
    "            recommendations[key] = activities\n",
    "    \n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-24T02:57:35.605666Z",
     "start_time": "2018-01-24T02:57:34.613566Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'berlin': ['Europa-Center',\n",
       "  'Die Hackeschen Hoefe',\n",
       "  'Alexanderplatz',\n",
       "  'Science Center Spectrum',\n",
       "  'LEGOLAND Discovery Centre',\n",
       "  'Kindermuseum MachtMit',\n",
       "  'Alte Forsterei',\n",
       "  'Mercedes-Benz Arena Berlin',\n",
       "  'Computerspielemuseum'],\n",
       " 'budapest': ['Liszt Ferenc Square',\n",
       "  'Originart Gallery',\n",
       "  'WestEnd City Center',\n",
       "  'Miniversum',\n",
       "  'Palace of Wonders',\n",
       "  'Semmelweis Museum of Medical History (Orvostorteneti Muzeum)',\n",
       "  'Groupama Arena',\n",
       "  'Budapest Pinball Museum',\n",
       "  'Stade Puskas Ferenc'],\n",
       " 'chicago': ['The Magnificent Mile',\n",
       "  'Devon Avenue',\n",
       "  \"Bloomingdale's\",\n",
       "  \"Chicago Children's Museum\",\n",
       "  'Adler Planetarium',\n",
       "  'Museum of Science and Industry',\n",
       "  'Guaranteed Rate Field',\n",
       "  'United Center',\n",
       "  'Wrigley Field']}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations([\"Little Five Points\", \"Fernbank Science Center\", \"Georgia Dome\"], \"atlanta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
